{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLijJWHGEy1M",
        "outputId": "846aeb56-b202-4521-e8ab-ee7ca650969a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gvTuyfOrLkoc",
        "outputId": "91c603f8-442a-4178-8e3c-e5bdf5a8307b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2540580524.py:8: DtypeWarning: Columns (0,10,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ S·ªë d√≤ng: 2003129\n",
            "üîπ C√°c c·ªôt: ['author', 'average_rating', 'bought_together', 'categories', 'description', 'details', 'features', 'images', 'main_category', 'parent_asin', 'price', 'rating_number', 'store', 'subtitle', 'title', 'videos']\n",
            "üîπ 5 d√≤ng ƒë·∫ßu ti√™n:\n",
            "  author  average_rating  bought_together  \\\n",
            "0    NaN             5.0              NaN   \n",
            "1    NaN             4.4              NaN   \n",
            "2    NaN             5.0              NaN   \n",
            "3    NaN             3.0              NaN   \n",
            "4    NaN             4.8              NaN   \n",
            "\n",
            "                                          categories  \\\n",
            "0  ['Automotive', 'Motorcycle & Powersports', 'Pa...   \n",
            "1  ['Automotive', 'Tires & Wheels', 'Accessories ...   \n",
            "2                                                 []   \n",
            "3  ['Automotive', 'Interior Accessories', 'Consol...   \n",
            "4  ['Automotive', 'Replacement Parts', 'Brake Sys...   \n",
            "\n",
            "                                         description  \\\n",
            "0  ['Compatible with Suzuki modelsGSX1100E 1100 1...   \n",
            "1  [\"Type : Long Spline, Closed End  Thread Pitch...   \n",
            "2  ['030156-40 Features: -Use for power unit cani...   \n",
            "3  ['Product Details:', 'Fits Car Model: Dodge Jo...   \n",
            "4  ['At Cardone, quality is the foundation of our...   \n",
            "\n",
            "                                             details  \\\n",
            "0  {'Manufacturer': 'Caltric', 'Brand': 'Caltric'...   \n",
            "1  {'Material': 'Steel', 'Fastener Type': 'Lock',...   \n",
            "2  {'Manufacturer': 'Eureka', 'Brand': 'Unknown',...   \n",
            "3  {'Manufacturer': 'Okutech', 'Brand': 'OkuTech'...   \n",
            "4  {'Manufacturer': 'Cardone Service Plus', 'Bran...   \n",
            "\n",
            "                                            features  \\\n",
            "0                                                 []   \n",
            "1  ['Note: Fit for aftermarket wheels only, not f...   \n",
            "2                                                 []   \n",
            "3  ['Black Retractable SUV Cargo Security Shade C...   \n",
            "4  ['Meets or exceeds OE performance and original...   \n",
            "\n",
            "                                              images main_category  \\\n",
            "0  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive   \n",
            "1  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive   \n",
            "2  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive   \n",
            "3  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive   \n",
            "4  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive   \n",
            "\n",
            "  parent_asin   price  rating_number           store subtitle  \\\n",
            "0  B00J9I1BD4    13.0              1         Caltric      NaN   \n",
            "1  B076PZ9X5R     NaN             59             APL      NaN   \n",
            "2  B00CMEHS34     NaN              2         Unknown      NaN   \n",
            "3  B09MWGTYL3  139.99              1         OkuTech      NaN   \n",
            "4  B009EJV2Y6   35.76              5  Amazon Renewed      NaN   \n",
            "\n",
            "                                               title videos  \n",
            "0  Caltric 3 Pack Oil Filter Compatible with Suzu...     []  \n",
            "1  APL 24 14x1.5 Acorn Spline Wheel Lug Nuts Blac...     []  \n",
            "2                                           Vent Cap     []  \n",
            "3  OkuTech Black Retractable Cargo Cover Rear Car...     []  \n",
            "4  Cardone Service Plus 14-1090 Remanufactured Ca...     []  \n",
            "\n",
            "üîπ M·ªôt s·ªë c·ªôt review:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['rating', 'text', 'asin', 'user_id', 'timestamp'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2540580524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Xem th·ª≠ v√†i c·ªôt quan tr·ªçng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüîπ M·ªôt s·ªë c·ªôt review:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'asin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['rating', 'text', 'asin', 'user_id', 'timestamp'] not in index\""
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n file sample (kh√¥ng c·∫ßn save_path)\n",
        "file_path = \"/content/drive/MyDrive/Dataset/Automotive_meta.csv\"\n",
        "\n",
        "# ƒê·ªçc file CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ki·ªÉm tra th√¥ng tin c∆° b·∫£n\n",
        "print(\"üîπ S·ªë d√≤ng:\", len(df))\n",
        "print(\"üîπ C√°c c·ªôt:\", df.columns.tolist())\n",
        "print(\"üîπ 5 d√≤ng ƒë·∫ßu ti√™n:\")\n",
        "print(df.head())\n",
        "\n",
        "# Xem th·ª≠ v√†i c·ªôt quan tr·ªçng\n",
        "print(\"\\nüîπ M·ªôt s·ªë c·ªôt review:\")\n",
        "print(df[['rating', 'title', 'text', 'asin', 'user_id', 'timestamp']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJH1MjP3LklY",
        "outputId": "6e5e6306-0e22-47bb-84e9-b551ef44cdb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ S·ªë d√≤ng: 20000\n",
            "üîπ C√°c c·ªôt: ['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase']\n",
            "üîπ 5 d√≤ng ƒë·∫ßu ti√™n:\n",
            "   rating                                              title  \\\n",
            "0     5.0                          Awesome brush and scraper   \n",
            "1     3.0  Can't read the atomic weight on it but everyth...   \n",
            "2     1.0                                               Junk   \n",
            "3     5.0                       Great tires.  Fast shipping.   \n",
            "4     1.0        Why do you keep deleting my reviews Amazon?   \n",
            "\n",
            "                                                text images        asin  \\\n",
            "0  Awesome brush and scraper. Works like a champ ...     []  B000BPLNXC   \n",
            "1  Can't read the atomic weight on it but everyth...     []  B00OOGK6CI   \n",
            "2                                  Cheap doesn‚Äôt fit     []  B01N94U01H   \n",
            "3  Great product!  Very fast shipping. Fit great ...     []  B01BVZSI6A   \n",
            "4  This product is Chinese junk. Save yourself a ...     []  B0751NHYB7   \n",
            "\n",
            "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
            "0  B000BPLNXC  AHKJMIK5JOTC2RQTHCXQECPYLWZA  1455821212000             0   \n",
            "1  B088Q9ZHVV  AE5ZNTM37TNFY3PHAEDZMUI2NB2A  1516445891127             0   \n",
            "2  B01N94U01H  AFIQS4B4ZHMRH6NLD2FQSBW3QXFQ  1541128482307             0   \n",
            "3  B01BVZSI6A  AHODN3GV4IO2OG5U7OEDJW3PLA3A  1621818943373             1   \n",
            "4  B07518LNZ8  AFWYR4LWJY2QM75RJHXOKJZH4HKQ  1560211007931            20   \n",
            "\n",
            "   verified_purchase  \n",
            "0               True  \n",
            "1               True  \n",
            "2               True  \n",
            "3               True  \n",
            "4              False  \n",
            "\n",
            "üîπ M·ªôt s·ªë c·ªôt review:\n",
            "   rating                                              title  \\\n",
            "0     5.0                          Awesome brush and scraper   \n",
            "1     3.0  Can't read the atomic weight on it but everyth...   \n",
            "2     1.0                                               Junk   \n",
            "3     5.0                       Great tires.  Fast shipping.   \n",
            "4     1.0        Why do you keep deleting my reviews Amazon?   \n",
            "5     5.0                                            Quality   \n",
            "6     5.0                                         EXCELLENT!   \n",
            "7     3.0                            Looks great..Didn't fit   \n",
            "8     5.0                    Great product at a great price!   \n",
            "9     1.0                               Not a dodge original   \n",
            "\n",
            "                                                text        asin  \\\n",
            "0  Awesome brush and scraper. Works like a champ ...  B000BPLNXC   \n",
            "1  Can't read the atomic weight on it but everyth...  B00OOGK6CI   \n",
            "2                                  Cheap doesn‚Äôt fit  B01N94U01H   \n",
            "3  Great product!  Very fast shipping. Fit great ...  B01BVZSI6A   \n",
            "4  This product is Chinese junk. Save yourself a ...  B0751NHYB7   \n",
            "5                                          Great buy  B00OL0FAVY   \n",
            "6  EXCELLENT<br />EXCELLENT<br />EXCELLENT<br />E...  B01KNWU66W   \n",
            "7  Loved the look but when I tried putting it on ...  B007SWVS04   \n",
            "8  Can't say enough good things about these runni...  B01FTGC9RQ   \n",
            "9  Cheep tail lamp for the price but it gets cond...  B000H8VYF0   \n",
            "\n",
            "                        user_id      timestamp  \n",
            "0  AHKJMIK5JOTC2RQTHCXQECPYLWZA  1455821212000  \n",
            "1  AE5ZNTM37TNFY3PHAEDZMUI2NB2A  1516445891127  \n",
            "2  AFIQS4B4ZHMRH6NLD2FQSBW3QXFQ  1541128482307  \n",
            "3  AHODN3GV4IO2OG5U7OEDJW3PLA3A  1621818943373  \n",
            "4  AFWYR4LWJY2QM75RJHXOKJZH4HKQ  1560211007931  \n",
            "5  AHUFCSH4WPN5BNXHFLGIH7GPOSBQ  1580073418359  \n",
            "6  AFZXKFRQOCG4AL2D2Y7H4QGLFVUQ  1630243058003  \n",
            "7  AFRLYQ3BILP2ZP74OU2XBTOCRQIA  1490681247000  \n",
            "8  AG5MFBAUBEOXZBOHDACAIOACUB2Q  1563572304119  \n",
            "9  AE3BKNJYTRBQJ7UC4RZEJV7QLMJQ  1569413020622  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n file sample (kh√¥ng c·∫ßn save_path)\n",
        "file_path = \"/content/drive/MyDrive/Dataset/Automotive_review_20k.csv\"\n",
        "\n",
        "# ƒê·ªçc file CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ki·ªÉm tra th√¥ng tin c∆° b·∫£n\n",
        "print(\"üîπ S·ªë d√≤ng:\", len(df))\n",
        "print(\"üîπ C√°c c·ªôt:\", df.columns.tolist())\n",
        "print(\"üîπ 5 d√≤ng ƒë·∫ßu ti√™n:\")\n",
        "print(df.head())\n",
        "\n",
        "# Xem th·ª≠ v√†i c·ªôt quan tr·ªçng\n",
        "print(\"\\nüîπ M·ªôt s·ªë c·ªôt review:\")\n",
        "print(df[['rating', 'title', 'text', 'asin', 'user_id', 'timestamp']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n file sample (kh√¥ng c·∫ßn save_path)\n",
        "file_path = \"/content/drive/MyDrive/Dataset/amazon_delivery.csv\"\n",
        "\n",
        "# ƒê·ªçc file CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ki·ªÉm tra th√¥ng tin c∆° b·∫£n\n",
        "print(\"üîπ S·ªë d√≤ng:\", len(df))\n",
        "print(\"üîπ C√°c c·ªôt:\", df.columns.tolist())\n",
        "print(\"üîπ 5 d√≤ng ƒë·∫ßu ti√™n:\")\n",
        "print(df.head())\n",
        "\n",
        "# Xem th·ª≠ v√†i c·ªôt quan tr·ªçng\n",
        "print(\"\\nüîπ M·ªôt s·ªë c·ªôt review:\")\n",
        "print(df[['rating', 'title', 'text', 'asin', 'user_id', 'timestamp']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "XjQMD57Z2Frc",
        "outputId": "c07745a8-406e-4fd2-a7b5-f2cfc448f235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ S·ªë d√≤ng: 43739\n",
            "üîπ C√°c c·ªôt: ['Order_ID', 'Agent_Age', 'Agent_Rating', 'Store_Latitude', 'Store_Longitude', 'Drop_Latitude', 'Drop_Longitude', 'Order_Date', 'Order_Time', 'Pickup_Time', 'Weather', 'Traffic', 'Vehicle', 'Area', 'Delivery_Time', 'Category']\n",
            "üîπ 5 d√≤ng ƒë·∫ßu ti√™n:\n",
            "        Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
            "0  ialx566343618         37           4.9       22.745049        75.892471   \n",
            "1  akqg208421122         34           4.5       12.913041        77.683237   \n",
            "2  njpu434582536         23           4.4       12.914264        77.678400   \n",
            "3  rjto796129700         38           4.7       11.003669        76.976494   \n",
            "4  zguw716275638         32           4.6       12.972793        80.249982   \n",
            "\n",
            "   Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time  \\\n",
            "0      22.765049       75.912471  2022-03-19   11:30:00    11:45:00   \n",
            "1      13.043041       77.813237  2022-03-25   19:45:00    19:50:00   \n",
            "2      12.924264       77.688400  2022-03-19   08:30:00    08:45:00   \n",
            "3      11.053669       77.026494  2022-04-05   18:00:00    18:10:00   \n",
            "4      13.012793       80.289982  2022-03-26   13:30:00    13:45:00   \n",
            "\n",
            "      Weather  Traffic      Vehicle            Area  Delivery_Time  \\\n",
            "0       Sunny    High   motorcycle           Urban             120   \n",
            "1      Stormy     Jam      scooter   Metropolitian             165   \n",
            "2  Sandstorms     Low   motorcycle           Urban             130   \n",
            "3       Sunny  Medium   motorcycle   Metropolitian             105   \n",
            "4      Cloudy    High      scooter   Metropolitian             150   \n",
            "\n",
            "      Category  \n",
            "0     Clothing  \n",
            "1  Electronics  \n",
            "2       Sports  \n",
            "3    Cosmetics  \n",
            "4         Toys  \n",
            "\n",
            "üîπ M·ªôt s·ªë c·ªôt review:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['rating', 'title', 'text', 'asin', 'user_id', 'timestamp'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3251162962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Xem th·ª≠ v√†i c·ªôt quan tr·ªçng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüîπ M·ªôt s·ªë c·ªôt review:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'asin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['rating', 'title', 'text', 'asin', 'user_id', 'timestamp'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvrq97ToiZcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDd3buf4iZaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#C√°c notebook th·ª±c hi·ªán project Hybrid Product-level DSS"
      ],
      "metadata": {
        "id": "V2aZvhbms0Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ƒê·∫ßu ti√™n: merge meta v·ªõi review_20k l·∫°i"
      ],
      "metadata": {
        "id": "zuxZCfe3s-zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "An9mTvsks0Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "meta_path = \"/content/drive/MyDrive/Dataset/Automotive_meta.csv\"\n",
        "review_path = \"/content/drive/MyDrive/Dataset/Automotive_review_20k.csv\"\n",
        "\n"
      ],
      "metadata": {
        "id": "85UbTqU1tHrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_meta = pd.read_csv(meta_path)\n",
        "df_review = pd.read_csv(review_path)\n",
        "\n",
        "print(\"üîπ Meta:\", df_meta.shape)\n",
        "print(\"üîπ Review:\", df_review.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC5bVXpx-D0A",
        "outputId": "aba35fa7-c69b-47d0-d4e8-a62c34451958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3704939189.py:1: DtypeWarning: Columns (0,10,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_meta = pd.read_csv(meta_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Meta: (2003129, 16)\n",
            "üîπ Review: (20000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Meta rows:\", len(df_meta))\n",
        "print(\"Review rows:\", len(df_review))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG6Y9zTbtHo_",
        "outputId": "a496eddc-df4d-4bfb-e0af-9eddff602065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta rows: 2003129\n",
            "Review rows: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge theo parent_asin\n",
        "merged = pd.merge(\n",
        "    df_review,\n",
        "    df_meta,\n",
        "    on=\"parent_asin\",\n",
        "    how=\"left\"  # ƒë·ªÉ gi·ªØ t·∫•t c·∫£ review, c√≥ th·ªÉ c√≥ nhi·ªÅu review cho 1 s·∫£n ph·∫©m\n",
        ")\n",
        "\n",
        "print(\"üîπ Merged:\", merged.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqzS0dtRtX1H",
        "outputId": "acdb5b88-b91a-45fc-ff35-4191e7173be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Merged: (20000, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM5BhNUstXqn",
        "outputId": "cc05b5eb-b36a-4c66-ae3d-d97a3477d402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   rating                                            title_x  \\\n",
            "0     5.0                          Awesome brush and scraper   \n",
            "1     3.0  Can't read the atomic weight on it but everyth...   \n",
            "2     1.0                                               Junk   \n",
            "3     5.0                       Great tires.  Fast shipping.   \n",
            "4     1.0        Why do you keep deleting my reviews Amazon?   \n",
            "5     5.0                                            Quality   \n",
            "6     5.0                                         EXCELLENT!   \n",
            "7     3.0                            Looks great..Didn't fit   \n",
            "8     5.0                    Great product at a great price!   \n",
            "9     1.0                               Not a dodge original   \n",
            "\n",
            "                                                text images_x        asin  \\\n",
            "0  Awesome brush and scraper. Works like a champ ...       []  B000BPLNXC   \n",
            "1  Can't read the atomic weight on it but everyth...       []  B00OOGK6CI   \n",
            "2                                  Cheap doesn‚Äôt fit       []  B01N94U01H   \n",
            "3  Great product!  Very fast shipping. Fit great ...       []  B01BVZSI6A   \n",
            "4  This product is Chinese junk. Save yourself a ...       []  B0751NHYB7   \n",
            "5                                          Great buy       []  B00OL0FAVY   \n",
            "6  EXCELLENT<br />EXCELLENT<br />EXCELLENT<br />E...       []  B01KNWU66W   \n",
            "7  Loved the look but when I tried putting it on ...       []  B007SWVS04   \n",
            "8  Can't say enough good things about these runni...       []  B01FTGC9RQ   \n",
            "9  Cheep tail lamp for the price but it gets cond...       []  B000H8VYF0   \n",
            "\n",
            "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
            "0  B000BPLNXC  AHKJMIK5JOTC2RQTHCXQECPYLWZA  1455821212000             0   \n",
            "1  B088Q9ZHVV  AE5ZNTM37TNFY3PHAEDZMUI2NB2A  1516445891127             0   \n",
            "2  B01N94U01H  AFIQS4B4ZHMRH6NLD2FQSBW3QXFQ  1541128482307             0   \n",
            "3  B01BVZSI6A  AHODN3GV4IO2OG5U7OEDJW3PLA3A  1621818943373             1   \n",
            "4  B07518LNZ8  AFWYR4LWJY2QM75RJHXOKJZH4HKQ  1560211007931            20   \n",
            "5  B00OL0FAVY  AHUFCSH4WPN5BNXHFLGIH7GPOSBQ  1580073418359             0   \n",
            "6  B092QTFZ1L  AFZXKFRQOCG4AL2D2Y7H4QGLFVUQ  1630243058003             0   \n",
            "7  B007SWVS04  AFRLYQ3BILP2ZP74OU2XBTOCRQIA  1490681247000             0   \n",
            "8  B01FTGC9RQ  AG5MFBAUBEOXZBOHDACAIOACUB2Q  1563572304119             0   \n",
            "9  B085VHQ8TP  AE3BKNJYTRBQJ7UC4RZEJV7QLMJQ  1569413020622             0   \n",
            "\n",
            "   verified_purchase  ...                                            details  \\\n",
            "0               True  ...  {'Brand': 'Mallory USA', 'Color': 'Colors May ...   \n",
            "1               True  ...  {'Manufacturer': 'CafePress', 'Brand': 'CafePr...   \n",
            "2               True  ...  {'Manufacturer': 'KaiTian Auto Part Co.,Ltd', ...   \n",
            "3               True  ...  {'Brand': 'ECustomRim', 'Seasons': 'Year Round...   \n",
            "4              False  ...  {'Brand': 'KT', 'Color': 'Red Demon Eye', 'Veh...   \n",
            "5               True  ...  {'Manufacturer': 'T1A TruBuilt 1 Automotive', ...   \n",
            "6               True  ...  {'Manufacturer': 'Leader Accessories', 'Brand'...   \n",
            "7               True  ...  {'Manufacturer': 'LA Auto Gear', 'Brand': 'LA ...   \n",
            "8               True  ...  {'Color': 'Black', 'Brand': 'Topline_autopart'...   \n",
            "9               True  ...  {'Manufacturer': 'TYC', 'Brand': 'TYC', 'Model...   \n",
            "\n",
            "                                            features  \\\n",
            "0  ['26 inches long for ample reach and compact s...   \n",
            "1  ['Express yourself with the design that fits y...   \n",
            "2  ['Condition: 100% Brand New', 'Non-slip Design...   \n",
            "3  ['Tire Size: 175/80D13 Load Range: C', 'Tire W...   \n",
            "4  ['Application:FZ09 / MT09 2014 2015 2016', 'Wh...   \n",
            "5  ['Includes 1 inside right door handle in OEM t...   \n",
            "6                                                 []   \n",
            "7  ['Bright 3D crystal art rhinestudded design', ...   \n",
            "8  ['Application: Compatible With 2004-2008 Ford ...   \n",
            "9  ['OE-comparable harness (no pigtail\" connector...   \n",
            "\n",
            "                                            images_y main_category  price  \\\n",
            "0  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  11.62   \n",
            "1  [{'thumb': 'https://m.media-amazon.com/images/...   Amazon Home   9.49   \n",
            "2  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  36.99   \n",
            "3  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive    NaN   \n",
            "4  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  449.0   \n",
            "5  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive   8.96   \n",
            "6  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  26.99   \n",
            "7  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive    NaN   \n",
            "8  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  187.0   \n",
            "9  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  43.44   \n",
            "\n",
            "  rating_number                      store subtitle  \\\n",
            "0         19555                Mallory USA      NaN   \n",
            "1             4                  CafePress      NaN   \n",
            "2            13                    Kaitian      NaN   \n",
            "3           362                 eCustomRim      NaN   \n",
            "4            11                         KT      NaN   \n",
            "5           170  T1A TruBuilt 1 Automotive      NaN   \n",
            "6          4587         Leader Accessories      NaN   \n",
            "7            41               LA Auto Gear      NaN   \n",
            "8            58           Topline_autopart      NaN   \n",
            "9           286                        TYC      NaN   \n",
            "\n",
            "                                             title_y videos  \n",
            "0  Mallory USA Mallory 532 Cool-Force 26‚Äù Snowbru...     []  \n",
            "1  CafePress Periodic Table of Elements Rectangle...     []  \n",
            "2  1pcs Non-Slip Dash Cover Dashboard Cover Sun V...     []  \n",
            "3  2-Pack Trailer Tire On Rim ST175/80D13 175/80 ...     []  \n",
            "4  KT for 2014 2015 2016 FZ09 / 2014 2015 2016 MT...     []  \n",
            "5  T1A Right Passenger Side Interior Door Handle ...     []  \n",
            "6  Leader Accessories Grey Waterproof Towel Auto ...     []  \n",
            "7  Blue & Green Turtles Gem Crystal Studded Rhine...     []  \n",
            "8  4\" Oval Black Side Step Nerf Bars Rail Running...     []  \n",
            "9  TYC 11-5702-01-1 Compatible with DODGE Left Re...     []  \n",
            "\n",
            "[10 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê∆∞·ªùng d·∫´n l∆∞u file CSV\n",
        "save_path = \"/content/drive/MyDrive/Dataset/Automotive_merged.csv\"\n",
        "\n",
        "# L∆∞u merged ra CSV\n",
        "merged.to_csv(save_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"‚úÖ ƒê√£ l∆∞u merged dataset v√†o: {save_path}\")\n",
        "print(\"üîπ S·ªë d√≤ng:\", len(merged))\n",
        "print(\"üîπ S·ªë c·ªôt:\", len(merged.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV3auutjtXnm",
        "outputId": "79404972-e521-4177-9c06-12e41aa36aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ƒê√£ l∆∞u merged dataset v√†o: /content/drive/MyDrive/Dataset/Automotive_merged.csv\n",
            "üîπ S·ªë d√≤ng: 20000\n",
            "üîπ S·ªë c·ªôt: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8U80UYvtXlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quFHOeh9tXig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import th∆∞ vi·ªán"
      ],
      "metadata": {
        "id": "42LEA7RSYFgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# Notebook: Hybrid Product-level DSS\n",
        "# - Input: product meta, reviews, delivery, (optional) expert_survey\n",
        "# - Output: product-level decision matrix + TOPSIS ranking csv\n",
        "# =============================\n",
        "\n",
        "# 0. Setup: imports\n",
        "import os\n",
        "import ast\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ML / NLP\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import spearmanr\n",
        "from math import sqrt\n",
        "# Utilities for TOPSIS / AHP\n",
        "import math\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "W4JDdbDziZXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 1. Paths - EDIT these to your files on Colab drive\n",
        "# -----------------------------------------------------------------------------\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/Dataset\"\n",
        "META_PATH = os.path.join(DRIVE_ROOT, \"Automotive_merged.csv\")        # product meta (parent_asin, price, average_rating, rating_number, main_category, title...)\n",
        "REV_PATH  = os.path.join(DRIVE_ROOT, \"Automotive_merged.csv\")  # reviews (asin,parent_asin,rating,text,...)\n",
        "DELIV_PATH= os.path.join(DRIVE_ROOT, \"amazon_delivery.csv\")        # delivery (Order_ID,Category,Delivery_Time,...)\n",
        "# Optional: expert survey file path if you have it:\n",
        "#SURVEY_PATH = os.path.join(DRIVE_ROOT, \"expert_survey.xlsx\")      # optional\n",
        "\n",
        "OUTPUT_DIR = os.path.join(DRIVE_ROOT, \"Hybrid_DSS_outputs\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "CgCld5kinQD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 2. Load datasets (preview)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"Loading meta ...\")\n",
        "meta = pd.read_csv(META_PATH)\n",
        "print(\"meta rows:\", len(meta))\n",
        "print(\"Columns:\", meta.columns.tolist())\n",
        "print(meta.head(2))\n",
        "\n",
        "print(\"\\nLoading reviews ...\")\n",
        "reviews = pd.read_csv(REV_PATH)\n",
        "print(\"reviews rows:\", len(reviews))\n",
        "print(reviews.columns.tolist())\n",
        "print(reviews.head(2))\n",
        "\n",
        "print(\"\\nLoading delivery ...\")\n",
        "delivery = pd.read_csv(DELIV_PATH)\n",
        "print(\"delivery rows:\", len(delivery))\n",
        "print(delivery.columns.tolist())\n",
        "print(delivery.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eic7vS0xSBkb",
        "outputId": "52e7591d-45a1-4958-a2b7-34943330fbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading meta ...\n",
            "meta rows: 20000\n",
            "Columns: ['rating', 'title_x', 'text', 'images_x', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase', 'author', 'average_rating', 'bought_together', 'categories', 'description', 'details', 'features', 'images_y', 'main_category', 'price', 'rating_number', 'store', 'subtitle', 'title_y', 'videos']\n",
            "   rating                                            title_x  \\\n",
            "0     5.0                          Awesome brush and scraper   \n",
            "1     3.0  Can't read the atomic weight on it but everyth...   \n",
            "\n",
            "                                                text images_x        asin  \\\n",
            "0  Awesome brush and scraper. Works like a champ ...       []  B000BPLNXC   \n",
            "1  Can't read the atomic weight on it but everyth...       []  B00OOGK6CI   \n",
            "\n",
            "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
            "0  B000BPLNXC  AHKJMIK5JOTC2RQTHCXQECPYLWZA  1455821212000             0   \n",
            "1  B088Q9ZHVV  AE5ZNTM37TNFY3PHAEDZMUI2NB2A  1516445891127             0   \n",
            "\n",
            "   verified_purchase  ...                                            details  \\\n",
            "0               True  ...  {'Brand': 'Mallory USA', 'Color': 'Colors May ...   \n",
            "1               True  ...  {'Manufacturer': 'CafePress', 'Brand': 'CafePr...   \n",
            "\n",
            "                                            features  \\\n",
            "0  ['26 inches long for ample reach and compact s...   \n",
            "1  ['Express yourself with the design that fits y...   \n",
            "\n",
            "                                            images_y main_category  price  \\\n",
            "0  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  11.62   \n",
            "1  [{'thumb': 'https://m.media-amazon.com/images/...   Amazon Home   9.49   \n",
            "\n",
            "  rating_number        store subtitle  \\\n",
            "0         19555  Mallory USA      NaN   \n",
            "1             4    CafePress      NaN   \n",
            "\n",
            "                                             title_y  videos  \n",
            "0  Mallory USA Mallory 532 Cool-Force 26‚Äù Snowbru...      []  \n",
            "1  CafePress Periodic Table of Elements Rectangle...      []  \n",
            "\n",
            "[2 rows x 25 columns]\n",
            "\n",
            "Loading reviews ...\n",
            "reviews rows: 20000\n",
            "['rating', 'title_x', 'text', 'images_x', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase', 'author', 'average_rating', 'bought_together', 'categories', 'description', 'details', 'features', 'images_y', 'main_category', 'price', 'rating_number', 'store', 'subtitle', 'title_y', 'videos']\n",
            "   rating                                            title_x  \\\n",
            "0     5.0                          Awesome brush and scraper   \n",
            "1     3.0  Can't read the atomic weight on it but everyth...   \n",
            "\n",
            "                                                text images_x        asin  \\\n",
            "0  Awesome brush and scraper. Works like a champ ...       []  B000BPLNXC   \n",
            "1  Can't read the atomic weight on it but everyth...       []  B00OOGK6CI   \n",
            "\n",
            "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
            "0  B000BPLNXC  AHKJMIK5JOTC2RQTHCXQECPYLWZA  1455821212000             0   \n",
            "1  B088Q9ZHVV  AE5ZNTM37TNFY3PHAEDZMUI2NB2A  1516445891127             0   \n",
            "\n",
            "   verified_purchase  ...                                            details  \\\n",
            "0               True  ...  {'Brand': 'Mallory USA', 'Color': 'Colors May ...   \n",
            "1               True  ...  {'Manufacturer': 'CafePress', 'Brand': 'CafePr...   \n",
            "\n",
            "                                            features  \\\n",
            "0  ['26 inches long for ample reach and compact s...   \n",
            "1  ['Express yourself with the design that fits y...   \n",
            "\n",
            "                                            images_y main_category  price  \\\n",
            "0  [{'thumb': 'https://m.media-amazon.com/images/...    Automotive  11.62   \n",
            "1  [{'thumb': 'https://m.media-amazon.com/images/...   Amazon Home   9.49   \n",
            "\n",
            "  rating_number        store subtitle  \\\n",
            "0         19555  Mallory USA      NaN   \n",
            "1             4    CafePress      NaN   \n",
            "\n",
            "                                             title_y  videos  \n",
            "0  Mallory USA Mallory 532 Cool-Force 26‚Äù Snowbru...      []  \n",
            "1  CafePress Periodic Table of Elements Rectangle...      []  \n",
            "\n",
            "[2 rows x 25 columns]\n",
            "\n",
            "Loading delivery ...\n",
            "delivery rows: 43739\n",
            "['Order_ID', 'Agent_Age', 'Agent_Rating', 'Store_Latitude', 'Store_Longitude', 'Drop_Latitude', 'Drop_Longitude', 'Order_Date', 'Order_Time', 'Pickup_Time', 'Weather', 'Traffic', 'Vehicle', 'Area', 'Delivery_Time', 'Category']\n",
            "        Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
            "0  ialx566343618         37           4.9       22.745049        75.892471   \n",
            "1  akqg208421122         34           4.5       12.913041        77.683237   \n",
            "\n",
            "   Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time Weather  \\\n",
            "0      22.765049       75.912471  2022-03-19   11:30:00    11:45:00   Sunny   \n",
            "1      13.043041       77.813237  2022-03-25   19:45:00    19:50:00  Stormy   \n",
            "\n",
            "  Traffic      Vehicle            Area  Delivery_Time     Category  \n",
            "0   High   motorcycle           Urban             120     Clothing  \n",
            "1    Jam      scooter   Metropolitian             165  Electronics  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "glE5u2O_WF8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 3. CLEAN & NORMALIZE product meta\n",
        "# -----------------------------------------------------------------------------\n",
        "# Use parent_asin as product id if available\n",
        "if 'parent_asin' in meta.columns:\n",
        "    meta = meta.rename(columns={'parent_asin':'product_id'})\n",
        "elif 'asin' in meta.columns:\n",
        "    meta = meta.rename(columns={'asin':'product_id'})\n",
        "else:\n",
        "    # fallback: assume index as product id\n",
        "    meta['product_id'] = meta.index.astype(str)\n",
        "\n",
        "# numeric conversions\n",
        "meta['price'] = pd.to_numeric(meta.get('price', np.nan), errors='coerce')\n",
        "meta['average_rating'] = pd.to_numeric(meta.get('average_rating', np.nan), errors='coerce')\n",
        "meta['rating_number'] = pd.to_numeric(meta.get('rating_number', 0), errors='coerce').fillna(0)\n",
        "\n",
        "# fill missing reasonably\n",
        "meta['price'] = meta['price'].fillna(meta['price'].median())\n",
        "meta['average_rating'] = meta['average_rating'].fillna(meta['average_rating'].median())\n",
        "\n",
        "# normalize category column name\n",
        "for c in ['main_category','category','categories','main_cat']:\n",
        "    if c in meta.columns:\n",
        "        meta['category'] = meta[c].astype(str)\n",
        "        break\n",
        "if 'category' not in meta.columns:\n",
        "    meta['category'] = 'unknown'\n",
        "\n",
        "# reduce to unique products (meta may have duplicates)\n",
        "meta = meta.drop_duplicates(subset=['product_id']).reset_index(drop=True)\n",
        "print(\"Meta after cleaning:\", meta.shape)"
      ],
      "metadata": {
        "id": "0QsqQPrbSHDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d100f7e8-8d22-4eae-f67c-1d3310776624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta after cleaning: (17350, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Review"
      ],
      "metadata": {
        "id": "l-Q7rRF_WKgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 4. REVIEW -> Review_Score per product (sentiment analysis)\n",
        "#    - We train a simple TF-IDF + Logistic Regression binary sentiment\n",
        "#    - Label rule: rating>=4 -> positive, <=2 -> negative, 3 -> neutral (drop or map to neutral)\n",
        "# -----------------------------------------------------------------------------\n",
        "# ensure columns\n",
        "reviews['product_id'] = reviews.get('parent_asin', reviews.get('asin', '')).astype(str)\n",
        "reviews['rating'] = pd.to_numeric(reviews['rating'], errors='coerce')\n",
        "\n",
        "# create sentiment label\n",
        "def label_sent(r):\n",
        "    if pd.isna(r): return np.nan\n",
        "    if r >= 4: return 1\n",
        "    if r <= 2: return 0\n",
        "    return np.nan  # neutral\n",
        "reviews['sent_label'] = reviews['rating'].apply(label_sent)\n",
        "\n",
        "# keep only labeled (positive/negative) for training\n",
        "rev_train = reviews[reviews['sent_label'].isin([0,1])].copy()\n",
        "print(\"Reviews labeled for training:\", len(rev_train))\n",
        "\n",
        "# basic text clean\n",
        "def clean_text(s):\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = str(s)\n",
        "    # minimal cleaning\n",
        "    s = s.replace(\"<br />\", \" \").lower()\n",
        "    return s\n",
        "\n",
        "rev_train['text_clean'] = rev_train['text'].apply(clean_text)\n",
        "\n",
        "# sample if very large\n",
        "SAMPLE_N = 150000\n",
        "if len(rev_train) > SAMPLE_N:\n",
        "    rev_train = rev_train.sample(SAMPLE_N, random_state=42)\n"
      ],
      "metadata": {
        "id": "25EHDJefSNNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8396626f-e8e4-4d06-b609-aec715a693ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews labeled for training: 18830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "tfv = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')\n",
        "X_tfidf = tfv.fit_transform(rev_train['text_clean'])\n",
        "y = rev_train['sent_label']\n",
        "\n",
        "# train/test\n",
        "Xtr, Xte, ytr, yte = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "clf.fit(Xtr, ytr)\n",
        "y_pred = clf.predict(Xte)\n",
        "print(\"\\nSentiment model eval:\")\n",
        "print(\"Accuracy:\", accuracy_score(yte, y_pred))\n",
        "print(classification_report(yte, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH_rfjZoWSZl",
        "outputId": "3cfd4d57-c6c1-4500-fc56-aaf392334091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment model eval:\n",
            "Accuracy: 0.9012214551248009\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.86      0.74       629\n",
            "         1.0       0.97      0.91      0.94      3137\n",
            "\n",
            "    accuracy                           0.90      3766\n",
            "   macro avg       0.81      0.88      0.84      3766\n",
            "weighted avg       0.92      0.90      0.91      3766\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict per-review probabilities for all reviews (or restrict)\n",
        "# To save time, we aggregate per product using up-to-N most recent reviews per product\n",
        "# Prepare mapping: for each product, sample up to 200 reviews and compute mean predicted prob\n",
        "tf = tfv  # naming\n",
        "clf_model = clf\n",
        "\n",
        "prod_sent = []\n",
        "grouped = reviews.groupby('product_id')\n",
        "for pid, g in tqdm(grouped, total=min(5000, len(grouped))):\n",
        "    # limit reviews per product to speed up\n",
        "    texts = g['text'].dropna().astype(str).tolist()[:200]\n",
        "    if len(texts)==0:\n",
        "        continue\n",
        "    Xs = tf.transform(texts)\n",
        "    probs = clf_model.predict_proba(Xs)[:,1]  # probability positive\n",
        "    prod_sent.append({'product_id': pid, 'review_pos_mean': float(probs.mean()), 'review_pos_median': float(np.median(probs)), 'review_count': len(texts)})\n",
        "\n",
        "prod_sent_df = pd.DataFrame(prod_sent)\n",
        "print(\"Aggregated sentiment for products:\", prod_sent_df.shape)\n",
        "prod_sent_df.to_csv(os.path.join(OUTPUT_DIR, 'product_sentiment_model.csv'), index=False)\n",
        "\n",
        "# Merge sentiment into meta (will drop products with no reviews later)\n",
        "meta = meta.merge(prod_sent_df[['product_id','review_pos_mean','review_count']], on='product_id', how='left')\n",
        "meta['review_pos_mean'] = meta['review_pos_mean'].fillna(0.0)\n",
        "meta['review_count'] = meta['review_count'].fillna(0).astype(int)\n",
        "\n",
        "# Optional review_score on 1-5 scale:\n",
        "meta['review_score_5'] = meta['review_pos_mean'] * 5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQmWq2cwWZlk",
        "outputId": "e63e5abf-74c5-4f7c-f1fb-124904b16507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17350it [00:20, 837.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated sentiment for products: (17345, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sale"
      ],
      "metadata": {
        "id": "NB0sNP_4Wjj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 5. SALES_SCORE from product meta (Sales proxy + ML)\n",
        "#    - We do not have ground-truth sales. We'll use proxy: proxy_sales = rating_number * average_rating\n",
        "#    - Train a regressor to predict proxy_sales from product features (price, average_rating, review_score...)\n",
        "#    - Output normalized Sales_Score in [0,1]\n",
        "# -----------------------------------------------------------------------------\n",
        "# Prepare features\n",
        "meta['proxy_sales'] = meta['rating_number'] * meta['average_rating']   # simple proxy\n",
        "# Avoid huge skew by log1p\n",
        "meta['proxy_sales_log'] = np.log1p(meta['proxy_sales'])\n",
        "\n",
        "feat_cols = []\n",
        "# numeric features\n",
        "meta['price'] = pd.to_numeric(meta['price'], errors='coerce').fillna(meta['price'].median())\n",
        "feat_cols += ['price','average_rating','rating_number','review_pos_mean']\n",
        "# category encode top-k categories as dummies (or label encode)\n",
        "topk = meta['category'].value_counts().head(30).index.tolist()\n",
        "meta['category_short'] = meta['category'].apply(lambda x: x if x in topk else 'other')\n",
        "dummies = pd.get_dummies(meta['category_short'], prefix='cat', drop_first=True)\n",
        "X = pd.concat([meta[feat_cols].reset_index(drop=True), dummies.reset_index(drop=True)], axis=1)\n",
        "y = meta['proxy_sales_log'].values"
      ],
      "metadata": {
        "id": "FVZoHQOcWlS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "ATaWxkP5Z8eF",
        "outputId": "a5621816-ff16-4082-f10c-76df22e9df2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "16ad4d6d00924fd3bb600cb1d6cff008"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train/test small sample (to keep quick)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "reg = RandomForestRegressor(n_estimators=150, n_jobs=-1, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"Sales proxy reg RMSE (log scale):\", rmse)\n",
        "\n",
        "# Predict for all products\n",
        "meta['sales_pred_log'] = reg.predict(X)\n",
        "# normalize to 0-1\n",
        "scaler = MinMaxScaler()\n",
        "meta['Sales_Score'] = scaler.fit_transform(meta['sales_pred_log'].values.reshape(-1,1)).ravel()\n",
        "\n",
        "# Save product-level base outputs\n",
        "meta_out = meta[['product_id','title'] + feat_cols + ['review_pos_mean','review_count','proxy_sales','Sales_Score']]\n",
        "meta_out.to_csv(os.path.join(OUTPUT_DIR,'products_with_sales_and_review.csv'), index=False)\n",
        "print(\"Saved products_with_sales_and_review.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "beyBwqICWsK1",
        "outputId": "d78ae447-a6b4-4837-ad60-f57ff6d311ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "got an unexpected keyword argument 'squared'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-351875840.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sales proxy reg RMSE (log scale):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# Map *args/**kwargs to the function signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m         \"\"\"\n\u001b[0;32m-> 3280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3267\u001b[0m                 )\n\u001b[1;32m   3268\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3269\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m   3270\u001b[0m                     'got an unexpected keyword argument {arg!r}'.format(\n\u001b[1;32m   3271\u001b[0m                         arg=next(iter(kwargs))))\n",
            "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train/test small sample (to keep quick)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "reg = RandomForestRegressor(n_estimators=150, n_jobs=-1, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# T√≠nh RMSE th·ªß c√¥ng (kh√¥ng c·∫ßn squared=False)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Sales proxy reg RMSE (log scale):\", rmse)\n",
        "\n",
        "# Predict for all products\n",
        "meta['sales_pred_log'] = reg.predict(X)\n",
        "\n",
        "# normalize to 0-1\n",
        "scaler = MinMaxScaler()\n",
        "meta['Sales_Score'] = scaler.fit_transform(meta['sales_pred_log'].values.reshape(-1,1)).ravel()\n",
        "\n",
        "# ch·ªçn c·ªôt title h·ª£p l·ªá (∆∞u ti√™n title, n·∫øu kh√¥ng c√≥ th√¨ d√πng title_x, n·∫øu kh√¥ng c√≥ n·ªØa th√¨ d√πng title_y)\n",
        "if 'title' in meta.columns:\n",
        "    title_col = 'title'\n",
        "elif 'title_x' in meta.columns:\n",
        "    title_col = 'title_x'\n",
        "elif 'title_y' in meta.columns:\n",
        "    title_col = 'title_y'\n",
        "else:\n",
        "    raise KeyError(\"Kh√¥ng t√¨m th·∫•y c·ªôt title/title_x/title_y trong meta\")\n",
        "\n",
        "# build output dataframe\n",
        "meta_out = meta[['product_id', title_col] + feat_cols + [\n",
        "    'review_pos_mean','review_count','proxy_sales','Sales_Score'\n",
        "]]\n",
        "\n",
        "# save to CSV\n",
        "meta_out.to_csv(os.path.join(OUTPUT_DIR, 'products_with_sales_and_review.csv'), index=False)\n",
        "print(\"Saved products_with_sales_and_review.csv (title column used:\", title_col, \")\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74b7xyVicxFG",
        "outputId": "00a825b8-bb0c-4025-b68f-d664be4a1c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales proxy reg RMSE (log scale): 0.012261207369123167\n",
            "Saved products_with_sales_and_review.csv (title column used: title_x )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Delivery"
      ],
      "metadata": {
        "id": "hDj2Y-WNe8s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 6. DELIVERY dataset -> Delivery_Score per category (proxy)\n",
        "#    - compute category-level metrics and map to each product by product.category\n",
        "# -----------------------------------------------------------------------------\n",
        "# delivery has 'Category' column mapping to product category(s)\n",
        "delivery = delivery.rename(columns={c:c.strip() for c in delivery.columns})\n",
        "if 'Category' in delivery.columns:\n",
        "    delivery['category'] = delivery['Category'].astype(str)\n",
        "else:\n",
        "    # try other names\n",
        "    for c in delivery.columns:\n",
        "        if c.lower().startswith('cat'):\n",
        "            delivery['category'] = delivery[c].astype(str)\n",
        "            break\n",
        "delivery['Delivery_Time'] = pd.to_numeric(delivery.get('Delivery_Time', np.nan), errors='coerce')\n",
        "\n",
        "# compute per-category stats: avg delivery time, on-time ratio (we'll compute percentiles)\n",
        "cat_stats = delivery.groupby('category').agg(\n",
        "    mean_delivery_time = ('Delivery_Time','mean'),\n",
        "    median_delivery_time = ('Delivery_Time','median'),\n",
        "    count_orders = ('Order_ID','count')\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "AJjoOU9Pe-gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize mean_delivery_time to score (smaller time -> higher score)\n",
        "# we invert: lower time -> higher delivery_score\n",
        "tmp = cat_stats.copy()\n",
        "# handle NaNs\n",
        "tmp['mean_delivery_time'] = tmp['mean_delivery_time'].fillna(tmp['mean_delivery_time'].max())\n",
        "# normalization\n",
        "max_t = tmp['mean_delivery_time'].max()\n",
        "min_t = tmp['mean_delivery_time'].min()\n",
        "tmp['Delivery_Score_cat'] = 1 - (tmp['mean_delivery_time'] - min_t) / (max_t - min_t + 1e-9)\n",
        "cat_stats = tmp[['category','mean_delivery_time','count_orders','Delivery_Score_cat']]\n"
      ],
      "metadata": {
        "id": "3I0VafWMfA4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map Delivery_Score_cat to product meta via category mapping\n",
        "# we need mapping between meta.category and delivery.category; lower-case normalize\n",
        "cat_map_delivery = {c.lower(): c for c in cat_stats['category'].unique()}\n",
        "\n",
        "def find_delivery_score(cat_name):\n",
        "    if pd.isna(cat_name): return np.nan\n",
        "    # naive approach: direct lower-match for words\n",
        "    c = str(cat_name).lower()\n",
        "    for del_cat in cat_stats['category'].values:\n",
        "        if del_cat.lower() in c or c in del_cat.lower():\n",
        "            return float(cat_stats.loc[cat_stats['category']==del_cat,'Delivery_Score_cat'].values[0])\n",
        "    # fallback: try exact match of first token\n",
        "    for token in c.split():\n",
        "        if token in cat_map_delivery:\n",
        "            delcat = cat_map_delivery[token]\n",
        "            return float(cat_stats.loc[cat_stats['category']==delcat,'Delivery_Score_cat'].values[0])\n",
        "    return np.nan\n",
        "\n",
        "# apply mapping to meta['category']\n",
        "meta['Delivery_Score'] = meta['category'].apply(find_delivery_score)\n",
        "# fill missing with global mean\n",
        "meta['Delivery_Score'] = meta['Delivery_Score'].fillna(meta['Delivery_Score'].mean())\n",
        "\n",
        "# save cat_stats for transparency\n",
        "cat_stats.to_csv(os.path.join(OUTPUT_DIR,'delivery_category_stats.csv'), index=False)\n",
        "print(\"Saved delivery_category_stats.csv\")\n"
      ],
      "metadata": {
        "id": "nB83oHOifDS9",
        "outputId": "f91080b5-231d-4c81-efe5-aa89e6b23904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved delivery_category_stats.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fuzzy Expert Survey"
      ],
      "metadata": {
        "id": "152kUT09rR2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Helper: Saaty scale -> triangular fuzzy numbers (TFN)\n",
        "# -----------------------------\n",
        "SAATY_TFN = {\n",
        "    1: (1, 1, 1),\n",
        "    2: (1, 2, 3),\n",
        "    3: (2, 3, 4),\n",
        "    4: (3, 4, 5),\n",
        "    5: (4, 5, 6),\n",
        "    6: (5, 6, 7),\n",
        "    7: (6, 7, 8),\n",
        "    8: (7, 8, 9),\n",
        "    9: (8, 9, 9)\n",
        "}\n",
        "\n",
        "# Also provide reciprocals\n",
        "def reciprocal_tfn(t):\n",
        "    l, m, u = t\n",
        "    return (1.0/u, 1.0/m, 1.0/l)\n"
      ],
      "metadata": {
        "id": "Ms3q_Jd4rUJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Build fuzzy pairwise matrix from crisp pairwise matrix of Saaty ints\n",
        "# Input: A (n x n) with Saaty scale ints (1-9), A_ij = k means i vs j = k\n",
        "# Output: fuzzy_matrix shape (n,n,3)\n",
        "# -----------------------------\n",
        "def build_fuzzy_matrix_from_saaty(A):\n",
        "    A = np.array(A)\n",
        "    n = A.shape[0]\n",
        "    F = np.zeros((n,n,3), dtype=float)\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            val = A[i,j]\n",
        "            if val >= 1:\n",
        "                t = SAATY_TFN.get(int(val), (1,1,1))\n",
        "                F[i,j,:] = t\n",
        "            else:\n",
        "                # if <=0 treat as reciprocal of positive value (rare)\n",
        "                t = SAATY_TFN.get(int(abs(val)), (1,1,1))\n",
        "                F[i,j,:] = reciprocal_tfn(t)\n",
        "    return F\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uTFVjpPnryaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Chang's extent analysis for fuzzy AHP\n",
        "# Steps:\n",
        "# 1) compute fuzzy synthetic extent S_i = sum over j (M_i * ???) following Chang 1996\n",
        "# Implementation adapted: S_i = (sum_j M_ij) * ( sum_i sum_j M_ij )^{-1}\n",
        "# But with fuzzy numbers: we sum fuzzy numbers and compute degree of possibility\n",
        "# We'll implement the standard algorithm to derive weights (see Chang 1996 methodology)\n",
        "# -----------------------------\n",
        "\n",
        "def fuzzy_sum(fA):\n",
        "    # fA shape (n,3) representing sum of TFNs\n",
        "    return np.sum(fA, axis=0)\n",
        "\n",
        "def tf_add(a,b):\n",
        "    return (a[0]+b[0], a[1]+b[1], a[2]+b[2])\n",
        "\n",
        "def tf_reciprocal(a):\n",
        "    l,m,u = a\n",
        "    return (1.0/u, 1.0/m, 1.0/l)\n",
        "\n",
        "# degree of possibility V(M1 >= M2) for triangular numbers\n",
        "def degree_of_possibility(m1, m2):\n",
        "    l1, m1c, u1 = m1\n",
        "    l2, m2c, u2 = m2\n",
        "    if m1c >= m2c:\n",
        "        return 1.0\n",
        "    elif u1 <= l2:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return (u1 - l2) / ((u1 - m1c) + (m2c - l2) + 1e-12)\n",
        "\n",
        "\n",
        "def fuzzy_ahp_weights_from_fuzzy_matrix(F):\n",
        "    # F: (n,n,3) TFN pairwise\n",
        "    n = F.shape[0]\n",
        "    # Step 1: sum rows (fuzzy sum of each row)\n",
        "    row_sums = np.zeros((n,3), dtype=float)\n",
        "    for i in range(n):\n",
        "        s = np.array([0.0,0.0,0.0])\n",
        "        for j in range(n):\n",
        "            s += F[i,j,:]\n",
        "        row_sums[i,:] = s\n",
        "    # Step 2: sum all row_sums to get total\n",
        "    total = np.sum(row_sums, axis=0)\n",
        "    # Step 3: compute synthetic extent S_i = row_sum_i * (total)^{-1} where inverse is tf reciprocal\n",
        "    total_recip = tf_reciprocal(tuple(total))\n",
        "    S = np.zeros((n,3), dtype=float)\n",
        "    for i in range(n):\n",
        "        # multiply TFN by scalar? Actually multiply TFNs: (l1,l2,l3)*(1/L,1/M,1/U) -> approximate via componentwise multiplication\n",
        "        a = row_sums[i,:]\n",
        "        b = total_recip\n",
        "        S[i,0] = a[0]*b[0]\n",
        "        S[i,1] = a[1]*b[1]\n",
        "        S[i,2] = a[2]*b[2]\n",
        "    # Step 4: compute degree of possibility of S_i >= S_j\n",
        "    V = np.zeros((n,n), dtype=float)\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i==j:\n",
        "                V[i,j] = 0.0\n",
        "            else:\n",
        "                V[i,j] = degree_of_possibility(tuple(S[i]), tuple(S[j]))\n",
        "    # Step 5: for each i, compute d_i = min over j != i of V[i,j]\n",
        "    d = np.zeros(n, dtype=float)\n",
        "    for i in range(n):\n",
        "        d[i] = np.min(V[i, np.arange(n)!=i])\n",
        "    # Step 6: normalize d to sum to 1\n",
        "    if d.sum() == 0:\n",
        "        # fallback: use normalized middle values of S\n",
        "        middles = S[:,1]\n",
        "        weights = middles / middles.sum()\n",
        "    else:\n",
        "        weights = d / d.sum()\n",
        "    return weights, S, V\n",
        "\n"
      ],
      "metadata": {
        "id": "d1Hi1t5IsBC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# TOPSIS implementation (all criteria maximize by default; pass impacts vector to handle minimization)\n",
        "# -----------------------------\n",
        "\n",
        "def topsis(df, criteria_cols, weights, impacts=None):\n",
        "    # df: dataframe with decision rows\n",
        "    # weights: list or array len(criteria)\n",
        "    X = df[criteria_cols].values.astype(float)\n",
        "    # normalize\n",
        "    denom = np.sqrt((X**2).sum(axis=0))\n",
        "    Xn = X / denom\n",
        "    # apply weights\n",
        "    V = Xn * weights\n",
        "    # impacts: 1 for maximize, -1 for minimize\n",
        "    if impacts is None:\n",
        "        impacts = np.ones(len(criteria_cols))\n",
        "    # ideal best/worst considering impact\n",
        "    ideal_best = np.max(V * impacts, axis=0)\n",
        "    ideal_worst = np.min(V * impacts, axis=0)\n",
        "    d_pos = np.sqrt(((V - ideal_best)**2).sum(axis=1))\n",
        "    d_neg = np.sqrt(((V - ideal_worst)**2).sum(axis=1))\n",
        "    score = d_neg / (d_pos + d_neg + 1e-12)\n",
        "    return score\n",
        "\n",
        "# -----------------------------\n",
        "# VIKOR implementation\n",
        "# -----------------------------\n",
        "\n",
        "def vikor(df, criteria_cols, weights, impacts=None, v=0.5):\n",
        "    X = df[criteria_cols].values.astype(float)\n",
        "    m, n = X.shape\n",
        "    if impacts is None:\n",
        "        impacts = np.ones(n)\n",
        "    # For impacts: if maximize -> best = max, worst = min; if minimize -> vice versa\n",
        "    f_star = np.zeros(n)\n",
        "    f_minus = np.zeros(n)\n",
        "    for j in range(n):\n",
        "        if impacts[j] == 1:\n",
        "            f_star[j] = X[:,j].max()\n",
        "            f_minus[j] = X[:,j].min()\n",
        "        else:\n",
        "            f_star[j] = X[:,j].min()\n",
        "            f_minus[j] = X[:,j].max()\n",
        "    # compute S_i and R_i\n",
        "    S = np.zeros(m)\n",
        "    R = np.zeros(m)\n",
        "    for i in range(m):\n",
        "        sum_term = 0.0\n",
        "        max_term = 0.0\n",
        "        for j in range(n):\n",
        "            if f_star[j] - f_minus[j] == 0:\n",
        "                term = 0\n",
        "            else:\n",
        "                term = weights[j] * ( (f_star[j] - X[i,j]) / (f_star[j] - f_minus[j]) ) if impacts[j]==1 else weights[j] * ( (X[i,j] - f_star[j]) / (f_minus[j] - f_star[j]) )\n",
        "            sum_term += term\n",
        "            if term > max_term:\n",
        "                max_term = term\n",
        "        S[i] = sum_term\n",
        "        R[i] = max_term\n",
        "    S_star, S_minus = S.max(), S.min()\n",
        "    R_star, R_minus = R.max(), R.min()\n",
        "    Q = np.zeros(m)\n",
        "    for i in range(m):\n",
        "        if S_star - S_minus == 0:\n",
        "            S_term = 0\n",
        "        else:\n",
        "            S_term = (S[i] - S_minus) / (S_star - S_minus)\n",
        "        if R_star - R_minus == 0:\n",
        "            R_term = 0\n",
        "        else:\n",
        "            R_term = (R[i] - R_minus) / (R_star - R_minus)\n",
        "        Q[i] = v * S_term + (1-v) * R_term\n",
        "    return Q, S, R\n",
        "\n"
      ],
      "metadata": {
        "id": "0-28_5fUsGPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Example usage: load decision_matrix_product_level.csv created previously\n",
        "# -----------------------------\n",
        "if __name__ == '__main__':\n",
        "    import os\n",
        "    BASE = '/content/drive/MyDrive/Dataset/Hybrid_DSS_outputs'  # change if needed\n",
        "    dec_path = os.path.join(BASE, 'decision_matrix_product_level.csv')\n",
        "    if not os.path.exists(dec_path):\n",
        "        print('Please place decision_matrix_product_level.csv in', BASE)\n",
        "    else:\n",
        "        dm = pd.read_csv(dec_path)\n",
        "        # choose columns to use (these should match your decision matrix)\n",
        "        crits = ['Sales_Score','Review_Score','Delivery_Score','Expert_Score']\n",
        "        # ensure numeric and normalized scales roughly 0-1\n",
        "        # normalize columns to 0-1 (MinMax) for fairness\n",
        "        scaler = MinMaxScaler()\n",
        "        dm[crits] = scaler.fit_transform(dm[crits].values)\n",
        "        # ---------- Fuzzy AHP: build pairwise matrix (example) ----------\n",
        "        # If you want to supply a custom pairwise matrix, replace A below\n",
        "        # Here: assume criteria order = Sales, Review, Delivery, Expert\n",
        "        # Example Saaty matrix (you can change values or load from file)\n",
        "        A = np.array([\n",
        "            [1, 3, 5, 7],\n",
        "            [1/3, 1, 3, 5],\n",
        "            [1/5, 1/3, 1, 3],\n",
        "            [1/7, 1/5, 1/3, 1]\n",
        "        ])\n",
        "        # Convert A to integer Saaty values (map floats to nearest integer 1..9 or reciprocals)\n",
        "        # For positive ratios >1 we map to nearest int; for reciprocals we'll store as reciprocal by representing value <1\n",
        "        A_int = np.zeros_like(A)\n",
        "        for i in range(A.shape[0]):\n",
        "            for j in range(A.shape[1]):\n",
        "                val = A[i,j]\n",
        "                if val >= 1:\n",
        "                    A_int[i,j] = int(round(val))\n",
        "                else:\n",
        "                    # store as reciprocal by storing int of reciprocal and negative sign? Our build function expects positive ints for direct comparisons\n",
        "                    # Instead we'll build TFNs manually for <1\n",
        "                    A_int[i,j] = 1\n",
        "        # Build fuzzy matrix robustly: allow A to be non-integer - we'll construct TFN pairwise directly\n",
        "        n = A.shape[0]\n",
        "        F = np.zeros((n,n,3), dtype=float)\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                val = A[i,j]\n",
        "                if val >= 1:\n",
        "                    # map to nearest Saaty int bounded 1..9\n",
        "                    k = int(min(9,max(1, round(val))))\n",
        "                    F[i,j,:] = SAATY_TFN[k]\n",
        "                else:\n",
        "                    # reciprocal\n",
        "                    k = int(min(9,max(1, round(1.0/val))))\n",
        "                    F[i,j,:] = reciprocal_tfn(SAATY_TFN[k])\n",
        "        # compute fuzzy-ahp weights\n",
        "        weights_fuzzy, S, V = fuzzy_ahp_weights_from_fuzzy_matrix(F)\n",
        "        print('Fuzzy-AHP derived weights (sum=1):', weights_fuzzy)\n",
        "        # ---------- TOPSIS ----------\n",
        "        topsis_scores = topsis(dm, crits, weights_fuzzy, impacts=np.array([1,1,1,1]))\n",
        "        dm['topsis_score_fuzzy_ahp'] = topsis_scores\n",
        "        dm['topsis_rank_fuzzy_ahp'] = dm['topsis_score_fuzzy_ahp'].rank(ascending=False, method='min')\n",
        "        # ---------- VIKOR ----------\n",
        "        Q, Svals, Rvals = vikor(dm, crits, weights_fuzzy, impacts=np.array([1,1,1,1]), v=0.5)\n",
        "        dm['vikor_Q'] = Q\n",
        "        dm['vikor_rank'] = dm['vikor_Q'].rank(ascending=True, method='min')  # smaller Q better\n",
        "        # Save\n",
        "        outpath = os.path.join(BASE, 'mcdm_fuzzyahp_topsis_vikor.csv')\n",
        "        dm.to_csv(outpath, index=False)\n",
        "        print('Saved MCDM outputs to', outpath)\n",
        "        # ranking stability: spearman correlation between TOPSIS and VIKOR ranks\n",
        "        rho, p = spearmanr(dm['topsis_rank_fuzzy_ahp'], dm['vikor_rank'])\n",
        "        print('Spearman correlation (topsis vs vikor ranks): rho=%.4f, p=%.4g' % (rho,p))\n",
        "        # print top 10 products by each method\n",
        "        print('\\nTop 10 by TOPSIS:')\n",
        "        display(dm.sort_values('topsis_score_fuzzy_ahp', ascending=False).head(10)[['product_id','title','topsis_score_fuzzy_ahp','topsis_rank_fuzzy_ahp']])\n",
        "        print('\\nTop 10 by VIKOR (lowest Q):')\n",
        "        display(dm.sort_values('vikor_Q', ascending=True).head(10)[['product_id','title','vikor_Q','vikor_rank']])\n",
        "\n",
        "# End of notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0_LJ7oGsMfl",
        "outputId": "3916a912-3372-4de2-ae8f-1c4008e0a324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please place decision_matrix_product_level.csv in /content/drive/MyDrive/Dataset/Hybrid_DSS_outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ki·ªÉm tra"
      ],
      "metadata": {
        "id": "_pOMIyDGvinl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé B∆∞·ªõc 1. Ki·ªÉm tra d·ªØ li·ªáu trong c√°c file CSV\n",
        "\n",
        "B·∫°n c√≥ th·ªÉ ch·∫°y th·ª≠ trong notebook/Colab:"
      ],
      "metadata": {
        "id": "0Q15krMjwY2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Dataset/Hybrid_DSS_outputs\"  # ƒë·ªïi path theo c·ªßa b·∫°n\n",
        "\n",
        "files = [\n",
        "    \"delivery_category_stats.csv\",\n",
        "    \"product_sentiment_model.csv\",\n",
        "    \"products_aggregated.csv\",\n",
        "    \"products_with_sales_and_review.csv\"\n",
        "]\n",
        "\n",
        "for f in files:\n",
        "    print(f\"\\nüîπ {f}\")\n",
        "    df = pd.read_csv(f\"{base_path}/{f}\")\n",
        "    print(df.shape)      # s·ªë d√≤ng, c·ªôt\n",
        "    print(df.head(3))    # 3 d√≤ng ƒë·∫ßu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsKXNq_jvkR9",
        "outputId": "e0b0f789-022e-45e9-bc3f-fd3dd0c245f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ delivery_category_stats.csv\n",
            "(16, 4)\n",
            "   category  mean_delivery_time  count_orders  Delivery_Score_cat\n",
            "0   Apparel          132.048789          2726            0.008026\n",
            "1     Books          131.021601          2824            0.017684\n",
            "2  Clothing          130.483690          2667            0.022741\n",
            "\n",
            "üîπ product_sentiment_model.csv\n",
            "(17345, 4)\n",
            "   product_id  review_pos_mean  review_pos_median  review_count\n",
            "0  1599690403         0.692468           0.692468             1\n",
            "1  1609675932         0.742206           0.742206             1\n",
            "2  9539751047         0.872824           0.872824             1\n",
            "\n",
            "üîπ products_aggregated.csv\n",
            "(2003129, 17)\n",
            "         asin                                              title  price  \\\n",
            "0  B00J9I1BD4  Caltric 3 Pack Oil Filter Compatible with Suzu...   13.0   \n",
            "1  B076PZ9X5R  APL 24 14x1.5 Acorn Spline Wheel Lug Nuts Blac...   38.0   \n",
            "2  B00CMEHS34                                           Vent Cap   38.0   \n",
            "\n",
            "   average_rating  rating_number main_category  \\\n",
            "0             5.0              1    Automotive   \n",
            "1             4.4             59    Automotive   \n",
            "2             5.0              2    Automotive   \n",
            "\n",
            "                                             details  \\\n",
            "0  {'Manufacturer': 'Caltric', 'Brand': 'Caltric'...   \n",
            "1  {'Material': 'Steel', 'Fastener Type': 'Lock',...   \n",
            "2  {'Manufacturer': 'Eureka', 'Brand': 'Unknown',...   \n",
            "\n",
            "                                            features  \\\n",
            "0                                                 []   \n",
            "1  ['Note: Fit for aftermarket wheels only, not f...   \n",
            "2                                                 []   \n",
            "\n",
            "                                          categories    store  \\\n",
            "0  ['Automotive', 'Motorcycle & Powersports', 'Pa...  Caltric   \n",
            "1  ['Automotive', 'Tires & Wheels', 'Accessories ...      APL   \n",
            "2                                                 []  Unknown   \n",
            "\n",
            "                                   categories_parsed  \\\n",
            "0  ['Automotive', 'Motorcycle & Powersports', 'Pa...   \n",
            "1  ['Automotive', 'Tires & Wheels', 'Accessories ...   \n",
            "2                                                 []   \n",
            "\n",
            "                                     features_parsed  review_count  \\\n",
            "0                                                 []           0.0   \n",
            "1  ['Note: Fit for aftermarket wheels only, not f...           0.0   \n",
            "2                                                 []           0.0   \n",
            "\n",
            "   avg_review_rating  pos_ratio  avg_helpful  verified_ratio  \n",
            "0                5.0        1.0          NaN             0.0  \n",
            "1                4.4        1.0          NaN             0.0  \n",
            "2                5.0        1.0          NaN             0.0  \n",
            "\n",
            "üîπ products_with_sales_and_review.csv\n",
            "(17350, 10)\n",
            "   product_id                                            title_x  price  \\\n",
            "0  B000BPLNXC                          Awesome brush and scraper  11.62   \n",
            "1  B088Q9ZHVV  Can't read the atomic weight on it but everyth...   9.49   \n",
            "2  B01N94U01H                                               Junk  36.99   \n",
            "\n",
            "   average_rating  rating_number  review_pos_mean  review_pos_mean.1  \\\n",
            "0             4.7          19555         0.834333           0.834333   \n",
            "1             3.6              4         0.466563           0.466563   \n",
            "2             3.8             13         0.022254           0.022254   \n",
            "\n",
            "   review_count  proxy_sales  Sales_Score  \n",
            "0             5      91908.5     0.837373  \n",
            "1             1         14.4     0.159391  \n",
            "2             1         49.4     0.251940  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëâ M·ª•c ti√™u: x√°c nh·∫≠n d·ªØ li·ªáu ƒë√£ c√≥ ƒë√∫ng c·∫•u tr√∫c (id s·∫£n ph·∫©m, c√°c score, category...)."
      ],
      "metadata": {
        "id": "i_GLn2z8wboE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé B∆∞·ªõc 2. Load l·∫°i model & vectorizer ƒë·ªÉ test review sentiment"
      ],
      "metadata": {
        "id": "NEB5RSwSw309"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load model + vectorizer\n",
        "vectorizer = joblib.load(f\"{base_path}/tfidf_vectorizer.joblib\")\n",
        "model = joblib.load(f\"{base_path}/sentiment_lr.joblib\")\n",
        "\n",
        "# Test th·ª≠ 1 c√¢u review\n",
        "sample_review = [\"This product is amazing, I really love it!\"]\n",
        "X_test = vectorizer.transform(sample_review)\n",
        "pred = model.predict(X_test)\n",
        "print(\"Review:\", sample_review[0])\n",
        "print(\"Sentiment prediction:\", pred[0])  # 1 = positive, 0 = negative (n·∫øu b·∫°n train nh∆∞ v·∫≠y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okbn3NKvwG-F",
        "outputId": "c830f659-84ae-4b61-a820-ef8a89bd6bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: This product is amazing, I really love it!\n",
            "Sentiment prediction: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HIGJmghzwfQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(f\"{base_path}/products_aggregated.csv\")\n",
        "\n",
        "# Ch·ªçn c√°c ti√™u ch√≠ ƒë·ªÉ x·∫øp h·∫°ng\n",
        "criteria = [\"Sentiment_Score\", \"Sales_Score\", \"Delivery_Score\"]\n",
        "\n",
        "X = df[criteria].values\n",
        "scaler = MinMaxScaler()\n",
        "X_norm = scaler.fit_transform(X)\n",
        "\n",
        "# Tr·ªçng s·ªë (gi·∫£ s·ª≠ b·∫±ng nhau)\n",
        "weights = np.array([1/3, 1/3, 1/3])\n",
        "\n",
        "# Ideal best & worst\n",
        "ideal_best = X_norm.max(axis=0)\n",
        "ideal_worst = X_norm.min(axis=0)\n",
        "\n",
        "# Kho·∫£ng c√°ch\n",
        "dist_best = np.linalg.norm((X_norm - ideal_best) * weights, axis=1)\n",
        "dist_worst = np.linalg.norm((X_norm - ideal_worst) * weights, axis=1)\n",
        "\n",
        "# T√≠nh score TOPSIS\n",
        "topsis_score = dist_worst / (dist_best + dist_worst)\n",
        "df[\"TOPSIS_Score\"] = topsis_score\n",
        "df = df.sort_values(\"TOPSIS_Score\", ascending=False)\n",
        "\n",
        "print(df.head(10)[[\"ProductID\",\"TOPSIS_Score\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "IbndAIsGwSEM",
        "outputId": "dd0c2c41-dc5b-4730-bc17-dbea6e56ced8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['Sentiment_Score', 'Sales_Score', 'Delivery_Score'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-940410911.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentiment_Score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sales_Score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Delivery_Score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcriteria\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Sentiment_Score', 'Sales_Score', 'Delivery_Score'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Dataset/Hybrid_DSS_outputs\"\n",
        "\n",
        "df_prod = pd.read_csv(f\"{base_path}/products_with_sales_and_review.csv\")\n",
        "df_cat = pd.read_csv(f\"{base_path}/delivery_category_stats.csv\")\n",
        "\n",
        "print(\"Products shape:\", df_prod.shape)\n",
        "print(\"Category stats shape:\", df_cat.shape)\n",
        "print(df_prod.head(2))\n",
        "print(df_cat.head(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTUkCwTUzC4d",
        "outputId": "d4046c6c-fdf9-416a-9a62-acb2b35c482f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products shape: (17350, 10)\n",
            "Category stats shape: (16, 4)\n",
            "   product_id                                            title_x  price  \\\n",
            "0  B000BPLNXC                          Awesome brush and scraper  11.62   \n",
            "1  B088Q9ZHVV  Can't read the atomic weight on it but everyth...   9.49   \n",
            "\n",
            "   average_rating  rating_number  review_pos_mean  review_pos_mean.1  \\\n",
            "0             4.7          19555         0.834333           0.834333   \n",
            "1             3.6              4         0.466563           0.466563   \n",
            "\n",
            "   review_count  proxy_sales  Sales_Score  \n",
            "0             5      91908.5     0.837373  \n",
            "1             1         14.4     0.159391  \n",
            "  category  mean_delivery_time  count_orders  Delivery_Score_cat\n",
            "0  Apparel          132.048789          2726            0.008026\n",
            "1    Books          131.021601          2824            0.017684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gi·∫£ s·ª≠ c·ªôt category ·ªü products l√† 'main_category' ho·∫∑c 'category'\n",
        "# N·∫øu kh√¥ng c√≥ th√¨ t·∫°m map b·∫±ng c√°ch kh√°c, ·ªü ƒë√¢y demo ƒë∆°n gi·∫£n\n",
        "if \"category\" not in df_prod.columns and \"main_category\" not in df_prod.columns:\n",
        "    df_prod[\"category\"] = \"Automotive\"  # fallback demo\n",
        "\n",
        "# Merge ƒë·ªÉ c√≥ Delivery_Score\n",
        "df_merge = df_prod.merge(df_cat[[\"category\", \"Delivery_Score_cat\"]],\n",
        "                         on=\"category\", how=\"left\")\n",
        "\n",
        "print(\"Merged shape:\", df_merge.shape)\n",
        "print(df_merge.head(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahRuf4M_zG5E",
        "outputId": "d968c85d-c3f5-4843-99a9-d85063d91808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged shape: (17350, 12)\n",
            "   product_id                                            title_x  price  \\\n",
            "0  B000BPLNXC                          Awesome brush and scraper  11.62   \n",
            "1  B088Q9ZHVV  Can't read the atomic weight on it but everyth...   9.49   \n",
            "\n",
            "   average_rating  rating_number  review_pos_mean  review_pos_mean.1  \\\n",
            "0             4.7          19555         0.834333           0.834333   \n",
            "1             3.6              4         0.466563           0.466563   \n",
            "\n",
            "   review_count  proxy_sales  Sales_Score    category  Delivery_Score_cat  \n",
            "0             5      91908.5     0.837373  Automotive                 NaN  \n",
            "1             1         14.4     0.159391  Automotive                 NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "criteria = [\"review_pos_mean\", \"Sales_Score\", \"Delivery_Score_cat\"]\n",
        "\n",
        "X = df_merge[criteria].fillna(0).values\n",
        "scaler = MinMaxScaler()\n",
        "X_norm = scaler.fit_transform(X)\n",
        "\n",
        "# Tr·ªçng s·ªë (gi·∫£ s·ª≠ b·∫±ng nhau, sau n√†y c√≥ th·ªÉ thay AHP/Fuzzy AHP)\n",
        "weights = np.array([1/3, 1/3, 1/3])\n",
        "\n",
        "# Ideal best & worst\n",
        "ideal_best = X_norm.max(axis=0)\n",
        "ideal_worst = X_norm.min(axis=0)\n",
        "\n",
        "# Kho·∫£ng c√°ch\n",
        "dist_best = np.linalg.norm((X_norm - ideal_best) * weights, axis=1)\n",
        "dist_worst = np.linalg.norm((X_norm - ideal_worst) * weights, axis=1)\n",
        "\n",
        "# T√≠nh score TOPSIS\n",
        "topsis_score = dist_worst / (dist_best + dist_worst)\n",
        "df_merge[\"TOPSIS_Score\"] = topsis_score\n"
      ],
      "metadata": {
        "id": "4ywpzwKQzJGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top10 = df_merge.sort_values(\"TOPSIS_Score\", ascending=False).head(10)\n",
        "print(top10[[\"product_id\",\"title_x\",\"review_pos_mean\",\"Sales_Score\",\"Delivery_Score_cat\",\"TOPSIS_Score\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8A5Q0iozLT0",
        "outputId": "1ed82777-5048-46f8-c6ed-604fc2e3e8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       product_id                                     title_x  \\\n",
            "16485  B0BLVSKZZ7                   Nice kit and great value.   \n",
            "6592   B09241ZKNR                                  Five Stars   \n",
            "5097   B0C2GB5DKM                                       Smell   \n",
            "13020  B07T54ZK5D                                  Great Oil!   \n",
            "1196   B08Y8F1LZ4                                 comfortable   \n",
            "10832  B0BHKSQ84N  TOO BAD I'M TOO LAME TO KNOW HOW TO USE IT   \n",
            "5453   B07Y4G75RL            Not perfect bt gets the job done   \n",
            "80     B098HLJWVC                                  Five Stars   \n",
            "4318   B0BPHZX4F7                    Best snow and ice wiper!   \n",
            "4396   B0C7GWGWKQ                             Easy to install   \n",
            "\n",
            "       review_pos_mean  Sales_Score  Delivery_Score_cat  TOPSIS_Score  \n",
            "16485         0.971137     0.916484                 NaN      0.937961  \n",
            "6592          0.957771     0.881282                 NaN      0.911761  \n",
            "5097          0.995362     0.854951                 NaN      0.900421  \n",
            "13020         0.982993     0.852636                 NaN      0.897681  \n",
            "1196          0.968090     0.851433                 NaN      0.894584  \n",
            "10832         0.990607     0.845441                 NaN      0.893748  \n",
            "5453          0.912035     0.877599                 NaN      0.893629  \n",
            "80            0.967608     0.849002                 NaN      0.892902  \n",
            "4318          0.940780     0.855793                 NaN      0.890839  \n",
            "4396          0.998458     0.836125                 NaN      0.888234  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Dataset/Hybrid_DSS_outputs\"\n",
        "\n",
        "# Load datasets\n",
        "df_sales = pd.read_csv(f\"{base_path}/products_with_sales_and_review.csv\")\n",
        "df_meta = pd.read_csv(f\"{base_path}/products_aggregated.csv\", usecols=[\"asin\", \"main_category\"])\n",
        "df_delivery = pd.read_csv(f\"{base_path}/delivery_category_stats.csv\")\n",
        "\n",
        "# B1: merge sales + category\n",
        "df_merged = df_sales.merge(df_meta, left_on=\"product_id\", right_on=\"asin\", how=\"left\")\n",
        "\n",
        "# B2: merge delivery score theo main_category\n",
        "df_merged = df_merged.merge(df_delivery[[\"category\",\"Delivery_Score_cat\"]],\n",
        "                            left_on=\"main_category\", right_on=\"category\", how=\"left\")\n",
        "\n",
        "# B3: x·ª≠ l√Ω c·ªôt\n",
        "df_final = df_merged.drop(columns=[\"asin\", \"category\", \"review_pos_mean.1\"]) \\\n",
        "                    .rename(columns={\"review_pos_mean\":\"Review_Score\"})\n",
        "\n",
        "# Preview\n",
        "print(\"‚úÖ Unified dataset:\", df_final.shape)\n",
        "print(df_final.head(5))\n",
        "\n",
        "# Save ra file chu·∫©n h√≥a\n",
        "df_final.to_csv(f\"{base_path}/unified_dataset.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp0_iZV96lXG",
        "outputId": "61da2d87-9c89-42cc-d9d5-c6ee16ffe670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Unified dataset: (17350, 11)\n",
            "   product_id                                            title_x   price  \\\n",
            "0  B000BPLNXC                          Awesome brush and scraper   11.62   \n",
            "1  B088Q9ZHVV  Can't read the atomic weight on it but everyth...    9.49   \n",
            "2  B01N94U01H                                               Junk   36.99   \n",
            "3  B01BVZSI6A                       Great tires.  Fast shipping.   26.99   \n",
            "4  B07518LNZ8        Why do you keep deleting my reviews Amazon?  449.00   \n",
            "\n",
            "   average_rating  rating_number  Review_Score  review_count  proxy_sales  \\\n",
            "0             4.7          19555      0.834333             5      91908.5   \n",
            "1             3.6              4      0.466563             1         14.4   \n",
            "2             3.8             13      0.022254             1         49.4   \n",
            "3             4.8            362      0.991535             1       1737.6   \n",
            "4             2.8             11      0.173090             1         30.8   \n",
            "\n",
            "   Sales_Score main_category  Delivery_Score_cat  \n",
            "0     0.837373    Automotive                 NaN  \n",
            "1     0.159391   Amazon Home                 NaN  \n",
            "2     0.251940    Automotive                 NaN  \n",
            "3     0.526849    Automotive                 NaN  \n",
            "4     0.215505    Automotive                 NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = df_final.copy()\n",
        "df_eval[\"Delivery_Score_cat\"] = df_eval[\"Delivery_Score_cat\"].fillna(df_eval[\"Delivery_Score_cat\"].mean())\n"
      ],
      "metadata": {
        "id": "FH6C-UDx8WVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ================================\n",
        "# 1. Load dataset\n",
        "# ================================\n",
        "base_path = \"/content/drive/MyDrive/Dataset/Hybrid_DSS_outputs\"\n",
        "df = pd.read_csv(f\"{base_path}/unified_dataset.csv\")\n",
        "\n",
        "# Fill NA cho Delivery_Score_cat = mean\n",
        "df_eval = df.copy()\n",
        "df_eval[\"Delivery_Score_cat\"] = df_eval[\"Delivery_Score_cat\"].fillna(df_eval[\"Delivery_Score_cat\"].mean())\n",
        "\n",
        "# ================================\n",
        "# 2. Normalize d·ªØ li·ªáu\n",
        "# ================================\n",
        "criteria = [\"Review_Score\", \"Sales_Score\", \"Delivery_Score_cat\"]\n",
        "\n",
        "X = df_eval[criteria].values\n",
        "scaler = MinMaxScaler()\n",
        "X_norm = scaler.fit_transform(X)\n",
        "\n",
        "# Tr·ªçng s·ªë (·ªü ƒë√¢y gi·∫£ ƒë·ªãnh b·∫±ng nhau)\n",
        "weights = np.array([1/3, 1/3, 1/3])\n",
        "\n",
        "# ================================\n",
        "# 3. TOPSIS\n",
        "# ================================\n",
        "ideal_best = X_norm.max(axis=0)\n",
        "ideal_worst = X_norm.min(axis=0)\n",
        "\n",
        "dist_best = np.linalg.norm((X_norm - ideal_best) * weights, axis=1)\n",
        "dist_worst = np.linalg.norm((X_norm - ideal_worst) * weights, axis=1)\n",
        "\n",
        "topsis_score = dist_worst / (dist_best + dist_worst)\n",
        "df_eval[\"TOPSIS_Score\"] = topsis_score\n",
        "\n",
        "# ================================\n",
        "# 4. VIKOR\n",
        "# ================================\n",
        "f_star = X_norm.max(axis=0)   # best\n",
        "f_minus = X_norm.min(axis=0)  # worst\n",
        "\n",
        "# Si, Ri\n",
        "Si = np.sum(weights * (f_star - X_norm) / (f_star - f_minus + 1e-9), axis=1)\n",
        "Ri = np.max(weights * (f_star - X_norm) / (f_star - f_minus + 1e-9), axis=1)\n",
        "\n",
        "S_star, S_minus = Si.min(), Si.max()\n",
        "R_star, R_minus = Ri.min(), Ri.max()\n",
        "\n",
        "# Q v·ªõi v = 0.5\n",
        "v = 0.5\n",
        "Qi = v * (Si - S_star) / (S_minus - S_star + 1e-9) + (1-v) * (Ri - R_star) / (R_minus - R_star + 1e-9)\n",
        "\n",
        "df_eval[\"VIKOR_Score\"] = Qi\n",
        "\n",
        "# ================================\n",
        "# 5. Top 10 so s√°nh\n",
        "# ================================\n",
        "print(\"üîπ TOP 10 theo TOPSIS\")\n",
        "print(df_eval.sort_values(\"TOPSIS_Score\", ascending=False)\n",
        "      [[\"product_id\",\"title_x\",\"Review_Score\",\"Sales_Score\",\"Delivery_Score_cat\",\"TOPSIS_Score\"]]\n",
        "      .head(10))\n",
        "\n",
        "print(\"\\nüîπ TOP 10 theo VIKOR\")\n",
        "print(df_eval.sort_values(\"VIKOR_Score\", ascending=True)  # VIKOR: score c√†ng th·∫•p c√†ng t·ªët\n",
        "      [[\"product_id\",\"title_x\",\"Review_Score\",\"Sales_Score\",\"Delivery_Score_cat\",\"VIKOR_Score\"]]\n",
        "      .head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gKUDzVa86nl",
        "outputId": "7131987b-e9a2-436b-d8d5-b706044e6f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ TOP 10 theo TOPSIS\n",
            "       product_id                                            title_x  \\\n",
            "11363  B00UTZLIZ2  Great product. Easy to clean and condition lea...   \n",
            "16698  B00J5HP7SO                                         Five Stars   \n",
            "16485  B0BLVSKZZ7                          Nice kit and great value.   \n",
            "5097   B0C2GB5DKM                                              Smell   \n",
            "6592   B09241ZKNR                                         Five Stars   \n",
            "13020  B07T54ZK5D                                         Great Oil!   \n",
            "10832  B0BHKSQ84N         TOO BAD I'M TOO LAME TO KNOW HOW TO USE IT   \n",
            "4396   B0C7GWGWKQ                                    Easy to install   \n",
            "1196   B08Y8F1LZ4                                        comfortable   \n",
            "15441  B0C4ZJR34C                                         Good value   \n",
            "\n",
            "       Review_Score  Sales_Score  Delivery_Score_cat  TOPSIS_Score  \n",
            "11363      0.982910     0.656563            1.000000      0.818278  \n",
            "16698      0.969955     0.656548            1.000000      0.817098  \n",
            "16485      0.971137     0.916484            0.212623      0.626702  \n",
            "5097       0.995362     0.854951            0.212623      0.620304  \n",
            "6592       0.957771     0.881282            0.212623      0.619366  \n",
            "13020      0.982993     0.852636            0.212623      0.618219  \n",
            "10832      0.990607     0.845441            0.212623      0.618059  \n",
            "4396       0.998458     0.836125            0.212623      0.617543  \n",
            "1196       0.968090     0.851433            0.212623      0.615885  \n",
            "15441      0.999746     0.823409            0.212623      0.615510  \n",
            "\n",
            "üîπ TOP 10 theo VIKOR\n",
            "       product_id                                            title_x  \\\n",
            "11363  B00UTZLIZ2  Great product. Easy to clean and condition lea...   \n",
            "16698  B00J5HP7SO                                         Five Stars   \n",
            "16485  B0BLVSKZZ7                          Nice kit and great value.   \n",
            "5097   B0C2GB5DKM                                              Smell   \n",
            "6592   B09241ZKNR                                         Five Stars   \n",
            "10832  B0BHKSQ84N         TOO BAD I'M TOO LAME TO KNOW HOW TO USE IT   \n",
            "13020  B07T54ZK5D                                         Great Oil!   \n",
            "4396   B0C7GWGWKQ                                    Easy to install   \n",
            "15441  B0C4ZJR34C                                         Good value   \n",
            "1196   B08Y8F1LZ4                                        comfortable   \n",
            "\n",
            "       Review_Score  Sales_Score  Delivery_Score_cat  VIKOR_Score  \n",
            "11363      0.982910     0.656563            1.000000     0.000000  \n",
            "16698      0.969955     0.656548            1.000000     0.002673  \n",
            "16485      0.971137     0.916484            0.212623     0.460444  \n",
            "5097       0.995362     0.854951            0.212623     0.468100  \n",
            "6592       0.957771     0.881282            0.212623     0.470412  \n",
            "10832      0.990607     0.845441            0.212623     0.471027  \n",
            "13020      0.982993     0.852636            0.212623     0.471114  \n",
            "4396       0.998458     0.836125            0.212623     0.471328  \n",
            "15441      0.999746     0.823409            0.212623     0.473673  \n",
            "1196       0.968090     0.851433            0.212623     0.474419  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 6. Ranking Stability Analysis\n",
        "# ================================\n",
        "# T√≠nh t∆∞∆°ng quan gi·ªØa TOPSIS & VIKOR\n",
        "corr = df_eval[\"TOPSIS_Score\"].corr(df_eval[\"VIKOR_Score\"])\n",
        "print(\"üîπ T∆∞∆°ng quan (corr) gi·ªØa TOPSIS & VIKOR:\", corr)\n",
        "\n",
        "# L·∫•y TOP 10 t·ª´ c·∫£ 2 ph∆∞∆°ng ph√°p\n",
        "top_topsis = set(df_eval.sort_values(\"TOPSIS_Score\", ascending=False)[\"product_id\"].head(10))\n",
        "top_vikor = set(df_eval.sort_values(\"VIKOR_Score\", ascending=True)[\"product_id\"].head(10))\n",
        "\n",
        "print(\"üîπ Giao gi·ªØa TOP 10 TOPSIS & VIKOR:\", top_topsis.intersection(top_vikor))\n",
        "print(\"üîπ S·ªë l∆∞·ª£ng SP tr√πng trong TOP 10:\", len(top_topsis.intersection(top_vikor)))\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7. Sensitivity Analysis (thay ƒë·ªïi tr·ªçng s·ªë)\n",
        "# ================================\n",
        "weight_scenarios = {\n",
        "    \"Equal (1/3,1/3,1/3)\": np.array([1/3, 1/3, 1/3]),\n",
        "    \"Review-heavy (0.5,0.3,0.2)\": np.array([0.5, 0.3, 0.2]),\n",
        "    \"Sales-heavy (0.2,0.5,0.3)\": np.array([0.2, 0.5, 0.3]),\n",
        "    \"Delivery-heavy (0.2,0.3,0.5)\": np.array([0.2, 0.3, 0.5])\n",
        "}\n",
        "\n",
        "def run_topsis(X_norm, weights):\n",
        "    ideal_best = X_norm.max(axis=0)\n",
        "    ideal_worst = X_norm.min(axis=0)\n",
        "    dist_best = np.linalg.norm((X_norm - ideal_best) * weights, axis=1)\n",
        "    dist_worst = np.linalg.norm((X_norm - ideal_worst) * weights, axis=1)\n",
        "    return dist_worst / (dist_best + dist_worst)\n",
        "\n",
        "# Ch·∫°y t·ª´ng k·ªãch b·∫£n\n",
        "for name, w in weight_scenarios.items():\n",
        "    df_eval[f\"TOPSIS_{name}\"] = run_topsis(X_norm, w)\n",
        "\n",
        "    # In top 3 s·∫£n ph·∫©m cho d·ªÖ quan s√°t\n",
        "    print(f\"\\nüîπ TOP 3 theo TOPSIS v·ªõi tr·ªçng s·ªë {name}:\")\n",
        "    print(df_eval.sort_values(f\"TOPSIS_{name}\", ascending=False)\n",
        "          [[\"product_id\",\"title_x\",f\"TOPSIS_{name}\"]].head(3))\n"
      ],
      "metadata": {
        "id": "j3K7Gs7U9aw2",
        "outputId": "91a9b11c-8eaf-4c76-9c88-3afe6827a7db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ T∆∞∆°ng quan (corr) gi·ªØa TOPSIS & VIKOR: -0.9549358700348477\n",
            "üîπ Giao gi·ªØa TOP 10 TOPSIS & VIKOR: {'B08Y8F1LZ4', 'B0C4ZJR34C', 'B07T54ZK5D', 'B0C7GWGWKQ', 'B09241ZKNR', 'B00UTZLIZ2', 'B0C2GB5DKM', 'B00J5HP7SO', 'B0BHKSQ84N', 'B0BLVSKZZ7'}\n",
            "üîπ S·ªë l∆∞·ª£ng SP tr√πng trong TOP 10: 10\n",
            "\n",
            "üîπ TOP 3 theo TOPSIS v·ªõi tr·ªçng s·ªë Equal (1/3,1/3,1/3):\n",
            "       product_id                                            title_x  \\\n",
            "11363  B00UTZLIZ2  Great product. Easy to clean and condition lea...   \n",
            "16698  B00J5HP7SO                                         Five Stars   \n",
            "16485  B0BLVSKZZ7                          Nice kit and great value.   \n",
            "\n",
            "       TOPSIS_Equal (1/3,1/3,1/3)  \n",
            "11363                    0.818278  \n",
            "16698                    0.817098  \n",
            "16485                    0.626702  \n",
            "\n",
            "üîπ TOP 3 theo TOPSIS v·ªõi tr·ªçng s·ªë Review-heavy (0.5,0.3,0.2):\n",
            "       product_id                                            title_x  \\\n",
            "11363  B00UTZLIZ2  Great product. Easy to clean and condition lea...   \n",
            "16698  B00J5HP7SO                                         Five Stars   \n",
            "16485  B0BLVSKZZ7                          Nice kit and great value.   \n",
            "\n",
            "       TOPSIS_Review-heavy (0.5,0.3,0.2)  \n",
            "11363                           0.845564  \n",
            "16698                           0.843321  \n",
            "16485                           0.774945  \n",
            "\n",
            "üîπ TOP 3 theo TOPSIS v·ªõi tr·ªçng s·ªë Sales-heavy (0.2,0.5,0.3):\n",
            "       product_id                                            title_x  \\\n",
            "11363  B00UTZLIZ2  Great product. Easy to clean and condition lea...   \n",
            "16698  B00J5HP7SO                                         Five Stars   \n",
            "1050   B0C7CZXBBT                                did nto want a cord   \n",
            "\n",
            "       TOPSIS_Sales-heavy (0.2,0.5,0.3)  \n",
            "11363                          0.738972  \n",
            "16698                          0.738469  \n",
            "1050                           0.673560  \n",
            "\n",
            "üîπ TOP 3 theo TOPSIS v·ªõi tr·ªçng s·ªë Delivery-heavy (0.2,0.3,0.5):\n",
            "       product_id                                            title_x  \\\n",
            "11363  B00UTZLIZ2  Great product. Easy to clean and condition lea...   \n",
            "16698  B00J5HP7SO                                         Five Stars   \n",
            "16485  B0BLVSKZZ7                          Nice kit and great value.   \n",
            "\n",
            "       TOPSIS_Delivery-heavy (0.2,0.3,0.5)  \n",
            "11363                             0.847351  \n",
            "16698                             0.846997  \n",
            "16485                             0.467204  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}